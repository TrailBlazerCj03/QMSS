{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensemble Models Continued"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adaboost Regressor (Scikit-learn docs)\n",
    "\n",
    "An AdaBoost regressor is a meta-estimator that begins by fitting a\n",
    "regressor on the original dataset and then fits additional copies of the\n",
    "regressor on the same dataset but where the weights of instances are\n",
    "adjusted according to the error of the current prediction. As such,\n",
    "subsequent regressors focus more on difficult cases.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.856924097598433\n",
      "0.9755362381269341\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# importing necessary libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "\n",
    "# Create the dataset\n",
    "rng = np.random.RandomState(1)\n",
    "X = np.linspace(0, 6, 100)[:, np.newaxis]\n",
    "y = np.sin(X).ravel() + np.sin(6 * X).ravel() + rng.normal(0, 0.1, X.shape[0])\n",
    "\n",
    "# Fit regression model\n",
    "regr_1 = DecisionTreeRegressor(max_depth=4)\n",
    "\n",
    "regr_2 = AdaBoostRegressor(DecisionTreeRegressor(max_depth=4),\n",
    "                          n_estimators=3000, random_state=rng)\n",
    "\n",
    "dectree = regr_1.fit(X, y)\n",
    "adaboosttreee = regr_2.fit(X, y)\n",
    "\n",
    "# Predict\n",
    "print(dectree.score(X, y))\n",
    "print(adaboosttreee.score(X, y))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "?AdaBoostRegressor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Use AdaBoostClassifier for classification problems\n",
    "\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.AdaBoostClassifier.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  XGboost adds in a regularization technique that evaluates how large a tree should by adding a regularization parameter \n",
    "#  to the cost function.  \n",
    "\n",
    "We will not cover xgboost in this class, but you can find some good tutorials to get started online.  For example, see the\n",
    "following:\n",
    "    \n",
    "https://xgboost.readthedocs.io/en/latest/python/python_intro.html"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
